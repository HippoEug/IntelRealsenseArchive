#include <iostream>
#include <fstream>
#include <sstream>
#include <string>
#include <map>
#include <algorithm>
#include <mutex>
#include <cmath>
#include <thread>
#include <chrono>
#include <conio.h>

#include <librealsense2/rs.hpp>
#include "example.hpp"

#define STB_IMAGE_WRITE_IMPLEMENTATION
#include "stb_image_write.h"

texture depth_image, color_image;

rs2::colorizer color_map;
rs2::pipeline pipe;

unsigned int choice;

void streamCapture();
void screenshotStream();
void getChoice();
void generate3D();
void getDistance();
void getMetaData();

int main() try {
	pipe.start();

	std::cout << "\n1. Capture: Stream Depth & RGB Cameras" << std::endl;
	std::cout << "2. Save a screenshot of the current Stream" << std::endl;
	std::cout << "3. Terminate Stream" << std::endl;
	std::cout << "4. Pointcloud: Generate and stream 3D Video" << std::endl;
	std::cout << "5. Distance: Get Distance" << std::endl;
	std::cout << "6. MetaData" << std::endl;
	std::cout << "Choice: ";
	std::cin >> choice;

	while (1) {
		switch (choice) {
		case 1: {
			std::thread t1(streamCapture);
			std::thread t2(getChoice);
			t1.join();
			t2.join();
			break;
		}
		case 2: {
			std::cout << "Taking a screenshot.. please wait" << std::endl;
			screenshotStream();
			getChoice();
			break;
		}
		case 3: {
			std::cout << "Stream Terminated" << std::endl;
			getChoice();
			break;
		}
		case 4: {
			std::thread t1(generate3D);
			std::thread t2(getChoice);
			t1.join();
			t2.join();
			break;
		}
		case 5: {
			getDistance();
			getChoice();
			break;
		}
		case 6: {
			getMetaData();
			break;
		}
		default: {
			std::cout << "\nINVALID OPTION" << std::endl;
			std::chrono::milliseconds(1000);
			getChoice();
		}
		}
	}
	return EXIT_SUCCESS;
}
catch (const rs2::error & e)
{
	std::cerr << "RealSense error calling " << e.get_failed_function() << "(" << e.get_failed_args() << "):\n    " << e.what() << std::endl;
	return EXIT_FAILURE;
}
catch (const std::exception& e)
{
	std::cerr << e.what() << std::endl;
	return EXIT_FAILURE;
}

void getMetaData() {
	// TODO
}

void getDistance() {
	rs2::frameset frames = pipe.wait_for_frames();

	// Try to get a frame of a depth image
	rs2::depth_frame depth = frames.get_depth_frame();

	// Get the depth frame's dimensions
	float width = depth.get_width();
	float height = depth.get_height();

	// Query the distance from the camera to the object in the center of the image
	float dist_to_center = depth.get_distance(width / 2, height / 2);

	std::cout << "The camera is facing an object " << dist_to_center << " meters away \r";
}

void generate3D() {
	window app(1280, 600, "Intel Realsense D435");

	glfw_state app_state;
	register_glfw_callbacks(app, app_state);

	rs2::pointcloud pc;
	rs2::points points;

	while (app && (choice == 4)) { // Check if application is still alive
		auto frames = pipe.wait_for_frames();

		auto depth = frames.get_depth_frame();

		// Generate the pointcloud and texture mappings
		points = pc.calculate(depth);

		auto color = frames.get_color_frame();

		// For cameras that don't have RGB sensor, we'll map the pointcloud to infrared instead of color
		if (!color)
			color = frames.get_infrared_frame();

		// Tell pointcloud object to map to this color frame
		pc.map_to(color);

		// Upload the color frame to OpenGL
		app_state.tex.upload(color);

		// Draw the pointcloud
		draw_pointcloud(app.width(), app.height(), app_state, points);
	}
}

void getChoice() {
	system("CLS");
	std::cout << "\n1. Capture: Stream Depth & RGB Cameras" << std::endl;
	std::cout << "2. Save a screenshot of the current Stream" << std::endl;
	std::cout << "3. Terminate Stream" << std::endl;
	std::cout << "4. Pointcloud: Generate and stream 3D Video" << std::endl;
	std::cout << "5. Distance: Get Distance" << std::endl;
	std::cout << "Choice: ";
	std::cin >> choice;
}

void screenshotStream() {
	for (auto i = 0; i < 30; ++i) pipe.wait_for_frames();

	// Wait for the next set of frames from the camera. Now that autoexposure, etc.
	// has settled, we will write these to disk
	for (auto&& frame : pipe.wait_for_frames())
	{
		// We can only save video frames as pngs, so we skip the rest
		if (auto vf = frame.as<rs2::video_frame>())
		{
			auto stream = frame.get_profile().stream_type();
			// Use the colorizer to get an rgb image for the depth stream
			if (vf.is<rs2::depth_frame>()) vf = color_map(frame);

			// Write images to disk
			std::stringstream png_file;
			png_file << "rs-save-to-disk-output-" << vf.get_profile().stream_name() << ".png";
			stbi_write_png(png_file.str().c_str(), vf.get_width(), vf.get_height(),
				vf.get_bytes_per_pixel(), vf.get_data(), vf.get_stride_in_bytes());
			std::cout << "Saved " << png_file.str() << std::endl;
		}
	}
}

void streamCapture() {
	window app(1280, 600, "Intel Realsense D435");

	while (app && (choice == 1)) { // Check if application is still alive
		rs2::frameset data = pipe.wait_for_frames(); // Wait for next set of frames from the camera

		rs2::frame depth = color_map(data.get_depth_frame()); // Find and colorize the depth data
		rs2::frame color = data.get_color_frame(); // Find the color data

		if (!color) { // For cameras that don't have RGB sensor, we'll render infrared frames instead of color
			color = data.get_infrared_frame();
		}

		// Render depth on to the first half of the screen and color on to the second
		depth_image.render(depth, { 0,               0, app.width() / 2, app.height() });
		color_image.render(color, { app.width() / 2, 0, app.width() / 2, app.height() });
	}
}
